{"cells":[{"cell_type":"code","execution_count":null,"id":"c7888a19","metadata":{"id":"c7888a19"},"outputs":[],"source":["import torch\n","\n","from facenet_pytorch import MTCNN, InceptionResnetV1\n","\n","# If required, create a face detection pipeline using MTCNN:\n","mtcnn = MTCNN(\n","    image_size=128, margin=0, min_face_size=20,\n","    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n","    device=0\n",")\n","\n","# Create an inception resnet (in eval mode):\n","resnet = InceptionResnetV1(pretrained='vggface2').eval()"]},{"cell_type":"code","execution_count":null,"id":"76e2c3db","metadata":{"id":"76e2c3db","outputId":"a1c1f58e-f42f-4aa1-fcb3-71b5a75c8171"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([64])\n","tensor(0., grad_fn=<DivBackward0>) tensor(1.0000, grad_fn=<DivBackward0>)\n"]}],"source":["img1 = torch.ones(64, 3, 128, 128)\n","img2 = torch.ones(64,3,128,128)\n","\n","# Get cropped and prewhitened image tensor\n","# img_cropped = mtcnn(img)\n","\n","# Calculate embedding (unsqueeze to add batch dimension)\n","img_embedding1 = resnet(img1)\n","img_embedding2 = resnet(img2)\n","\n","fsd = torch.sum(torch.abs((img_embedding1-img_embedding2)))/64\n","cos = torch.nn.CosineSimilarity(dim=1)\n","fss = torch.sum(cos(img_embedding1,img_embedding2))/64\n","print(fsd,fss)\n"]},{"cell_type":"code","execution_count":null,"id":"e1eb4000","metadata":{"id":"e1eb4000"},"outputs":[],"source":["def fsdcalc(real,fake):\n","        # If required, create a face detection pipeline using MTCNN:\n","    mtcnn = MTCNN(\n","        image_size=128, margin=0, min_face_size=20,\n","        thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n","        device=0\n","    )\n","\n","    # Create an inception resnet (in eval mode):\n","    resnet = InceptionResnetV1(pretrained='vggface2').eval()\n","    \n","    real = real.to(device='cpu')\n","    fake = fake.to(device='cpu')\n","    \n","    img_embedding1 = resnet(real)\n","    img_embedding2 = resnet(fake)\n","\n","    fsd = torch.sum(torch.abs((img_embedding1-img_embedding2)))/64\n","\n","    return fsd\n","    \n","    "]},{"cell_type":"code","execution_count":null,"id":"709f66a3","metadata":{"id":"709f66a3"},"outputs":[],"source":["def fsscalc(real,fake):\n","        # If required, create a face detection pipeline using MTCNN:\n","    mtcnn = MTCNN(\n","        image_size=128, margin=0, min_face_size=20,\n","        thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n","        device=0\n","    )\n","\n","    # Create an inception resnet (in eval mode):\n","    resnet = InceptionResnetV1(pretrained='vggface2').eval()\n","    \n","    real = real.to(device='cpu')\n","    fake = fake.to(device='cpu')\n","    \n","    img_embedding1 = resnet(real)\n","    img_embedding2 = resnet(fake)\n","\n","    cos = torch.nn.CosineSimilarity(dim=1)\n","\n","    fss = torch.sum(cos(img_embedding1,img_embedding2))/64\n","\n","    return fss"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}